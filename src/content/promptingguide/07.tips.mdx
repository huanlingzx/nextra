---
title: 提示词技巧
description: 编写有效提示词的技巧。
---

# **提示词技巧**

除了之前的核心原则，掌握一些具体的提示词技巧能够帮助我们更快地驾驭 LLM，获得更理想的输出。下面介绍几种基础且实用的技巧：


| **技巧名称**                              | **定义**                                                                                                                                                  | **适用场景**                                                                                               | **简单示例 (以中文任务为例)**                                                                                                                                                                                                                                                                                                                                                  |
| ----------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **零样本提示 (Zero-shot Prompting)**      | 直接向 LLM 发出指令或提问，不提供任何具体的任务完成示例，完全依赖模型在预训练阶段学到的知识和能力来理解并执行任务。                                    | 任务相对简单直接，LLM 的通用知识足以应对时（如简单的文本分类、常识问答、简单指令执行）。                   | “将以下句子翻译成英文：‘今天天气真好。’”<br /> “这段文字表达了积极还是消极的情绪？‘这家餐厅的菜品味道很一般。’”                                                                                                                                                                                                                                                          |
| **少样本提示 (Few-shot Prompting)**       | 在提示词中提供少量 (通常 1 到 5 个) 任务完成的示例 (输入-输出对)，向 LLM 展示期望的输出格式、风格或答案模式，从而引导其更好地完成类似任务。            | 当任务稍微复杂，或需要模型遵循特定格式、语气，或零样本提示效果不佳时。有助于提高输出的一致性和准确性。 | **情感分类示例**：<br /> 将以下评论分类为“好评”、“中评”或“差评”。<br /> 评论：这款耳机音质很棒！<br /> 分类：好评 <br /><br/ > 评论：物流速度有点慢。<br /> 分类：中评 <br /><br /> 评论：产品用了两天就坏了。<br /> 分类：[LLM 在此生成]                                                                                                                                                  |
| **零样本思维链提示 (Zero-shot CoT)**      | 在不提供解题示例的情况下，通过在提示末尾添加一句简单的引导语（如“让我们一步一步地思考”），来鼓励模型展现其思考过程，从而提高复杂推理任务的准确性。  | 适用于需要一定逻辑推理或计算，但又不想构建复杂少样本示例的场景。                                           | “小明有 5 个苹果，他给了小红 2 个，然后妈妈又给了他 3 个。小明现在有多少个苹果？让我们一步一步地思考。”                                                                                                                                                                                                                                                                      |
| **少样本思维链提示 (Few-shot CoT)**       | 在提示中提供一或多个包含完整解题步骤（思考过程）的示例，向模型清晰地展示如何进行逐步推理，然后让模型解决新的类似问题。                                | 适用于更复杂的推理任务，尤其是当零样本 CoT 效果不佳时，通过示例明确指导模型的思考路径。                    | **数学应用题示例**：<br /> 问：一个农场里有 12 只鸡和 8 头牛，它们一共有多少条腿？<br /> 答：鸡有 2 条腿，牛有 4 条腿。所以，12 只鸡有 12 \* 2 = 24 条腿。8 头牛有 8 \* 4 = 32 条腿。它们一共有 24 + 32 = 56 条腿。答案是 56。<br /><br/ > 问：一个停车场停了 9 辆汽车和 5 辆摩托车，它们一共有多少个轮子？（假设汽车 4 个轮子，摩托车 2 个轮子）<br /> 答：[LLM 在此生成思考过程和答案] |
| **角色扮演提示 (Role-playing Prompting)** | 指示 LLM 扮演一个特定的角色、身份或专家（如“你是一位经验丰富的导游”、“假设你是一名营养师”），从而使其输出更符合该角色的口吻、知识背景和思考方式。 | 需要特定风格、语气或专业视角的输出时，如撰写特定受众的文案、解释专业概念、进行创意写作、模拟面试等。       | “你现在是一位资深的园艺师。请向一个新手解释如何在阳台上成功种植番茄，需要注意哪些关键点？”<br />“扮演一位科幻小说家，构思一个关于未来城市交通的故事大纲。”                                                                                                                                                                                                                   |

下面我们对这些技巧进行更深入的解释：

* **零样本提示 (Zero-shot Prompting)**
  * 这是最直接、最简单的提示方式。您直接告诉模型要做什么，而不给它任何具体的例子。例如，您可以说：“总结一下这篇文章的主要观点。”或者“这首诗表达了什么情感？”模型会利用它在预训练时学到的海量知识和对语言的理解来尝试完成任务。
  * 这种方法对于那些模型已经非常熟悉并且相对直接的任务（如简单的翻译、常识问答、基础的文本分类）通常效果不错 。
* **少样本提示 (Few-shot Prompting)**
  * 当任务稍微复杂一些，或者您希望模型的输出遵循某种特定的格式或风格时，零样本提示可能就不够用了。这时，少样本提示就派上了用场。您需要在提示词中给模型提供一到几个（通常不超过五个）完整的“输入-输出”示例。这些示例就像是给模型看的“样板”，告诉它：“对于这样的输入，我希望得到那样的输出。”
  * 例如，如果您想让模型将非正式的句子改写成正式的句子，您可以这样提示：
    ```markdown
    将以下非正式表达改写为正式表达：
    非正式：老板说这事儿得快点搞定。
    正式：经理指示该事项需尽快处理。
    
    非正式：我觉得这个主意不咋地。
    正式：我认为此方案尚有改进空间。

    非正式：他们把会议给推迟了。
    正式：[LLM 在此生成正式表达]
    ```
  * 通过这些示例，模型能够更好地“学习”到您期望的转换规则和语言风格。一个值得注意的方面是，在构建少样本提示时，示例的**格式和结构的一致性**，以及示例所体现的**任务模式**，往往比示例内容本身的绝对正确性更为关键 。这意味着，即使示例中的某个标签或答案略有偏差，但只要整体格式清晰、任务模式明确，模型依然能从中学习到正确的处理方式。这为我们构建少样本提示降低了门槛，不必过分追求每个示例都完美无缺，更应关注示例的代表性和指导性。
* **思维链提示 (Chain-of-Thought, CoT) 入门**
  * 对于那些需要多步骤逻辑推理、数学计算或复杂问题分析的任务，仅仅给出问题本身，LLM 往往难以直接得到正确答案。思维链提示是一种旨在提升 LLM 在这类任务上表现的强大技巧 。
  * 其核心思想是引导模型**显式地展现出一步一步的思考过程或推理链条**，而不是直接跳到最终答案 。这就像我们在解决一个复杂的数学题时，会把解题步骤写出来一样。这些中间步骤为模型提供了更强的上下文信号，使其在预测最终答案时能够利用这些信号，从而提高准确性。
  * **零样本 CoT (Zero-shot CoT)**: 这是应用思维链最简单的方式。您只需要在您的原始问题提示后面，加上一句简单的引导语，比如“让我们一步一步地思考。”，“请逐步解释你的推理过程。”或者英文中常用的 "Let's think step by step." 。这句简单的话就能有效地“启动”模型的逐步推理模式。
    * *示例*：“一个书架上有三层，第一层有 15 本书，第二层比第一层多 5 本，第三层是第二层的一半。这个书架上总共有多少本书？让我们一步一步地思考。”
  * **少样本 CoT (Few-shot CoT)**: 当零样本 CoT 效果不够理想，或者问题更为复杂时，可以通过提供包含完整解题步骤的示例来更明确地指导模型。您需要在提示中给出几个“问题 + 详细思考步骤 + 答案”的完整范例，然后提出您想让模型解决的新问题 。
    * *示例*：

      ```markdown
      问：罗杰有5个网球。他又买了2罐网球，每罐有3个。他现在总共有多少个网球？
      答：罗杰开始有5个网球。他买了2罐，每罐3个，所以新买了 2 * 3 = 6 个网球。那么他总共有 5 + 6 = 11 个网球。答案是11。

      问：莉莉有32颗巧克力，她的姐姐有42颗。如果她们一起吃了35颗，她们总共还剩下多少颗巧克力？
      答：[LLM 在此生成思考过程和答案]
      ```

  * 需要注意的是，思维链提示的效果通常在参数规模较大的模型上更为显著（例如，参数量超过千亿的模型 ）。这并非是说模型真的在“思考”，而是通过引导模型生成一个更长、更详细的、包含了中间步骤的文本序列，这个序列恰好模拟了人类的逻辑推理过程，从而帮助模型更准确地逼近最终答案。
* **角色扮演提示 (Role-playing Prompting)**
  * 这是一种非常直观且有趣的提示技巧。您可以明确指示 LLM 扮演一个特定的角色、身份或专家，例如“你是一位经验丰富的市场营销专家”、“假设你是一名历史老师”、“请你扮演一位耐心的客服代表”等 。
  * 当模型被赋予一个角色后，它的回答往往会更贴近该角色的口吻、知识背景、思考方式和语言风格。这对于需要特定风格的文本生成、专业领域的知识解释、创意写作，甚至是模拟面试等场景都非常有用。
  * *示例*：“你是一位资深的旅行顾问。请为一个预算有限、喜欢自然风光和历史文化的大学生，规划一个为期 5 天的中国西南地区（例如云南或四川）的旅行路线建议，并说明推荐理由。”
  * 角色扮演之所以有效，可以理解为它激活了 LLM 在其庞大训练数据中与该特定角色相关的知识子集和语言模式 。例如，当您让模型扮演一名“海盗”，它就会倾向于使用在其训练数据中学习到的与海盗故事相关的词汇和表达方式。这使得我们能够以一种简单直观的方式来塑造模型的输出，而无需编写复杂的指令。
