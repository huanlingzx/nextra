---
title: 使用方法
description: 介绍大语言模型的使用方法。
---

import ExampleBlock from '../../components/ExampleBlock'
import ParameterInfo from '../../components/ParameterInfo'

# 4. 大语言模型使用方法

使用大语言模型其实非常简单，无论你是技术人员还是普通用户，都能轻松上手。现在有很多平台提供了大语言模型的访问方式，下面我将介绍几种常见的使用方式。

## 1. **通过官网使用**

最简单的方式就是通过官网直接使用大语言模型，比如[deepseek](https://chat.deepseek.com/ )，[通义千问qwen](https://chat.qwen.ai )。这些平台为普通用户提供了简单易用的界面，你只需要注册一个账号，就可以开始使用。你可以像聊天一样与模型互动，输入问题或需求，模型就会根据它学到的知识给出回答或生成相应的内容。

-   **适用对象**：任何没有编程经验的用户。
-   **使用方式**：只需输入问题或任务，模型会快速生成答案或文本。
-   **优点**：非常简便，无需任何技术背景，界面友好，容易上手。

deepseek 网页对话界面如下图所示：
![deepseek](/deepsekk-官网.png)

### 示例：

假设你需要写一封感谢信，只需要在输入框中输入，模型会生成一封感谢信，你可以直接使用或者稍作调整：
<ExampleBlock
  question="请帮我写一封感谢信，感谢我的同事最近帮助我完成了一个项目。"
  answer="尊敬的XXX，感谢您在过去的工作中提供的宝贵支持。您的贡献对我们团队至关重要，我深感荣幸能与您合作。"
/>

## 2. **通过API使用**

如果你是开发人员或有一定的技术背景，API是一个更灵活的选择。API（应用程序接口）允许你将大语言模型的功能集成到你的应用程序中。通过API，你可以设置不同的参数来精确控制模型的行为。例如，你可以控制文本的长度、语气、创意水平等。

-   **适用对象**：希望能更深入的使用大语言模型的人员。
-   **使用方式**：通过编程接口，将大语言模型的功能嵌入到自己的软件中。不过目前已经有人实现相关的软件，也可以很简单的就上手使用。
-   **优点**：灵活性高，可以定制化设置。

下面是[deepseek 文档](https://api-docs.deepseek.com/zh-cn/ )中通过python来使用api接口的示例：
```python filename="python"
# Please install OpenAI SDK first: `pip3 install openai`

from openai import OpenAI

client = OpenAI(api_key="<DeepSeek API Key>", base_url="https://api.deepseek.com")

response = client.chat.completions.create(
    model="deepseek-chat",
    messages=[
        {"role": "system", "content": "You are a helpful assistant"},
        {"role": "user", "content": "Hello"},
    ],
    stream=False
)

print(response.choices[0].message.content)
```

### 使用 API 接口时的参数设置

在使用大型语言模型的 API 接口时，了解和调整一些关键参数对于控制模型的输出行为至关重要。这些参数可以影响模型的创造性、多样性、准确性以及输出的长度。以下是一些常用的参数：

<ParameterInfo
  name="温度 (Temperature)"
  description="控制模型输出的随机性和创造性。温度值越高，模型输出越随机和多样；温度值越低，模型输出越确定和集中。"
  range="通常在 0 到 1 之间。"
  impact="高温度：适用于需要创意性、探索性或生成不同选项的任务。低温度：适用于需要准确性、一致性或生成事实性内容的任务。"
  suggestion="对于需要准确性的任务，使用较低的温度；对于需要创造性的任务，使用较高的温度。"
/>
<ParameterInfo
  name="Top-p (核采样)"
  description="控制模型在生成下一个词时考虑的词汇范围。Top-p 参数指定了一个概率阈值，模型只会从累积概率达到该阈值的最高概率词汇中进行采样。"
  range="通常在 0 到 1 之间。"
  impact="高 Top-p：模型会考虑更多的词汇选项，输出更具多样性。低 Top-p：模型只会考虑概率最高的少数词汇，输出更集中和确定。"
  suggestion="可以根据任务需求调整 Top-p。对于需要更多样性的输出，可以适当提高 Top-p。"
/>
<ParameterInfo
  name="最大输出长度 (Max Tokens)"
  description="限制模型生成的输出文本的最大长度（以 token 为单位）。一个 token 可以是一个词、一个标点符号或一个词的一部分。"
  range="通常有一个上限。"
  impact="控制输出的篇幅，达到限制时直接停止输出。"
  suggestion="根据你期望的输出长度设置该参数。注意，提示词本身也会占用 token 数量，总的 token 数量（提示词 + 输出）通常有一个上限。"
/>

**如何选择参数？**

选择合适的参数取决于你的具体任务需求：

-   **需要准确、事实性强的回答：**
    -   低温度（Temperature）
    -   低 Top-p
    -   适当的最大输出长度

-   **需要创意、多样性的生成：**
    -   高温度（Temperature）
    -   高 Top-p
    -   适当的最大输出长度

> **建议：** 通常建议从默认参数开始，然后根据输出效果逐步调整这些参数。
